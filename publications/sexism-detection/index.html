<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="A Transparent Pipeline for Identifying Sexism in Social Media: Combining Explainability with Model Prediction">
  <meta property="og:title" content="A Transparent Pipeline for Identifying Sexism in Social Media"/>
  <meta property="og:description" content="An explainable AI approach for detecting sexism in social media with transparent decision-making"/>
  <meta property="og:url" content="https://www.mdpi.com/2076-3417/14/19/8620"/>
  <meta name="twitter:title" content="A Transparent Pipeline for Identifying Sexism in Social Media">
  <meta name="twitter:description" content="An explainable AI approach for detecting sexism in social media with transparent decision-making">
  <meta name="keywords" content="Sexism Detection, Explainable AI, Social Media, NLP, LIME, SHAP, Hate Speech">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>A Transparent Pipeline for Identifying Sexism in Social Media</title>
  <link rel="icon" type="image/x-icon" href="../../Logo.png">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.css">

  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.js"></script>

  <style>
    :root {
      --primary-color: #2563eb;
      --secondary-color: #3b82f6;
      --accent-color: #60a5fa;
      --text-primary: #1e293b;
      --text-secondary: #64748b;
      --bg-light: #f8fafc;
      --bg-white: #ffffff;
      --border-color: #e2e8f0;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', sans-serif;
      color: var(--text-primary);
      line-height: 1.6;
      background-color: var(--bg-light);
    }

    /* Header Styles */
    .hero-section {
      background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
      color: white;
      padding: 80px 0 60px;
      position: relative;
      overflow: hidden;
    }

    .hero-section::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: url('data:image/svg+xml,%3Csvg width="60" height="60" viewBox="0 0 60 60" xmlns="http://www.w3.org/2000/svg"%3E%3Cg fill="none" fill-rule="evenodd"%3E%3Cg fill="%23ffffff" fill-opacity="0.05"%3E%3Cpath d="M36 34v-4h-2v4h-4v2h4v4h2v-4h4v-2h-4zm0-30V0h-2v4h-4v2h4v4h2V6h4V4h-4zM6 34v-4H4v4H0v2h4v4h2v-4h4v-2H6zM6 4V0H4v4H0v2h4v4h2V6h4V4H6z"/%3E%3C/g%3E%3C/g%3E%3C/svg%3E');
    }

    .hero-content {
      position: relative;
      z-index: 1;
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 20px;
      text-align: center;
    }

    .publication-title {
      font-size: 2.5rem;
      font-weight: 700;
      margin-bottom: 1.5rem;
      line-height: 1.2;
    }

    .authors-list {
      font-size: 1.1rem;
      margin-bottom: 0.5rem;
      opacity: 0.95;
    }

    .authors-list strong {
      font-weight: 600;
    }

    .affiliation {
      font-size: 1rem;
      opacity: 0.9;
      margin-bottom: 0.5rem;
    }

    .venue {
      font-size: 0.95rem;
      opacity: 0.85;
      font-style: italic;
      margin-bottom: 2rem;
    }

    .hero-buttons {
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
      justify-content: center;
      margin-top: 2rem;
    }

    .hero-button {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.75rem 1.5rem;
      background: rgba(255, 255, 255, 0.2);
      color: white;
      text-decoration: none;
      border-radius: 8px;
      font-weight: 500;
      transition: all 0.3s;
      border: 1px solid rgba(255, 255, 255, 0.3);
    }

    .hero-button:hover {
      background: rgba(255, 255, 255, 0.3);
      transform: translateY(-2px);
    }

    /* Navigation Bar */
    .nav-bar {
      background: white;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      position: sticky;
      top: 0;
      z-index: 100;
    }

    .nav-content {
      max-width: 1200px;
      margin: 0 auto;
      padding: 1rem 20px;
      display: flex;
      gap: 2rem;
      align-items: center;
      justify-content: center;
      overflow-x: auto;
    }

    .nav-link {
      color: var(--text-secondary);
      text-decoration: none;
      font-weight: 500;
      white-space: nowrap;
      padding: 0.5rem 1rem;
      border-radius: 6px;
      transition: all 0.3s;
    }

    .nav-link:hover {
      color: var(--primary-color);
      background: var(--bg-light);
    }

    /* Content Sections */
    .content-section {
      max-width: 1200px;
      margin: 0 auto;
      padding: 60px 20px;
    }

    .section-header {
      font-size: 2rem;
      font-weight: 700;
      color: var(--text-primary);
      margin-bottom: 2rem;
      position: relative;
      padding-left: 1rem;
    }

    .section-header::before {
      content: '';
      position: absolute;
      left: 0;
      top: 50%;
      transform: translateY(-50%);
      width: 4px;
      height: 24px;
      background: var(--primary-color);
      border-radius: 2px;
    }

    /* Abstract Box */
    .abstract-container {
      background: white;
      padding: 2.5rem;
      border-radius: 16px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
      margin-bottom: 3rem;
    }

    .abstract-text {
      color: var(--text-secondary);
      line-height: 1.8;
      text-align: justify;
    }

    .abstract-text p {
      margin-bottom: 1.25rem;
    }

    .abstract-text p:last-child {
      margin-bottom: 0;
    }

    /* Key Points Grid */
    .key-points-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 1.5rem;
      margin-bottom: 3rem;
    }

    .key-point-card {
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
      transition: all 0.3s;
      border-top: 3px solid var(--accent-color);
    }

    .key-point-card:hover {
      transform: translateY(-4px);
      box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
    }

    .key-point-icon {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      width: 48px;
      height: 48px;
      background: var(--bg-light);
      color: var(--primary-color);
      font-size: 1.25rem;
      border-radius: 12px;
      margin-bottom: 1rem;
    }

    .key-point-title {
      font-size: 1.15rem;
      font-weight: 600;
      color: var(--text-primary);
      margin-bottom: 0.75rem;
    }

    .key-point-description {
      color: var(--text-secondary);
      line-height: 1.6;
      font-size: 0.95rem;
    }

    /* Methodology Section */
    .methodology-container {
      background: white;
      padding: 2.5rem;
      border-radius: 16px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
    }

    .methodology-title {
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--text-primary);
      margin-bottom: 1.5rem;
      margin-top: 1.5rem;
    }

    .methodology-title:first-child {
      margin-top: 0;
    }

    .methodology-timeline {
      position: relative;
      padding-left: 2rem;
    }

    .methodology-timeline::before {
      content: '';
      position: absolute;
      left: 0;
      top: 0;
      bottom: 0;
      width: 2px;
      background: var(--border-color);
    }

    .timeline-item {
      position: relative;
      padding-bottom: 1.5rem;
    }

    .timeline-item:last-child {
      padding-bottom: 0;
    }

    .timeline-item::before {
      content: '';
      position: absolute;
      left: -2.5rem;
      top: 0.5rem;
      width: 12px;
      height: 12px;
      background: var(--primary-color);
      border-radius: 50%;
      border: 3px solid white;
      box-shadow: 0 0 0 2px var(--border-color);
    }

    .timeline-title {
      font-size: 1rem;
      font-weight: 600;
      color: var(--text-primary);
      margin-bottom: 0.5rem;
    }

    .timeline-description {
      color: var(--text-secondary);
      line-height: 1.6;
      font-size: 0.95rem;
    }

    .technique-list {
      list-style: none;
      padding: 0;
    }

    .technique-item {
      display: flex;
      align-items: flex-start;
      gap: 1rem;
      padding: 1rem 0;
      border-bottom: 1px solid var(--border-color);
    }

    .technique-item:last-child {
      border-bottom: none;
    }

    .technique-icon {
      width: 40px;
      height: 40px;
      background: var(--bg-light);
      color: var(--primary-color);
      border-radius: 8px;
      display: flex;
      align-items: center;
      justify-content: center;
      flex-shrink: 0;
    }

    .technique-content {
      flex: 1;
    }

    .technique-name {
      font-weight: 600;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .technique-desc {
      color: var(--text-secondary);
      font-size: 0.9rem;
    }

    /* Results Section */
    .results-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1.5rem;
      margin-bottom: 2rem;
    }

    .result-card {
      background: white;
      padding: 1.5rem;
      border-radius: 12px;
      text-align: center;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    .result-number {
      font-size: 2.5rem;
      font-weight: 700;
      color: var(--primary-color);
      margin-bottom: 0.5rem;
    }

    .result-label {
      color: var(--text-secondary);
      font-size: 0.9rem;
    }

    .results-details {
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    .results-details ul {
      list-style: none;
      padding: 0;
    }

    .results-details li {
      padding: 0.75rem 0;
      border-bottom: 1px solid var(--border-color);
      color: var(--text-secondary);
      display: flex;
      align-items: flex-start;
      gap: 0.75rem;
    }

    .results-details li:last-child {
      border-bottom: none;
    }

    .results-details li::before {
      content: '✓';
      color: var(--primary-color);
      font-weight: 600;
    }

    /* Resources Section */
    .resources-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 1rem;
    }

    .resource-item {
      background: white;
      padding: 1.25rem;
      border-radius: 10px;
      display: flex;
      align-items: center;
      gap: 1rem;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
      transition: all 0.3s;
    }

    .resource-item:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }

    .resource-icon {
      width: 40px;
      height: 40px;
      background: var(--bg-light);
      color: var(--primary-color);
      border-radius: 8px;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .resource-text {
      color: var(--text-secondary);
      font-size: 0.95rem;
    }

    .resource-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      color: var(--primary-color);
      text-decoration: none;
      font-weight: 500;
      margin-top: 1.5rem;
      transition: gap 0.3s;
    }

    .resource-link:hover {
      gap: 0.75rem;
    }

    /* Citation Box */
    .citation-box {
      background: var(--bg-light);
      border: 1px solid var(--border-color);
      border-radius: 12px;
      padding: 1.5rem;
      margin-top: 2rem;
      position: relative;
    }

    .citation-code {
      font-family: 'Courier New', monospace;
      font-size: 0.85rem;
      color: var(--text-primary);
      white-space: pre-wrap;
      word-break: break-all;
    }

    .copy-button {
      position: absolute;
      top: 1rem;
      right: 1rem;
      padding: 0.5rem 1rem;
      background: white;
      border: 1px solid var(--border-color);
      border-radius: 6px;
      cursor: pointer;
      font-size: 0.875rem;
      color: var(--text-secondary);
      transition: all 0.3s;
    }

    .copy-button:hover {
      background: var(--primary-color);
      color: white;
      border-color: var(--primary-color);
    }

    /* Footer */
    .paper-footer {
      background: white;
      padding: 3rem 0;
      margin-top: 4rem;
      border-top: 1px solid var(--border-color);
    }

    .footer-content {
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 20px;
      text-align: center;
    }

    .footer-links {
      display: flex;
      justify-content: center;
      gap: 2rem;
      margin-bottom: 2rem;
    }

    .footer-link {
      color: var(--text-secondary);
      text-decoration: none;
      font-size: 1.5rem;
      transition: color 0.3s;
    }

    .footer-link:hover {
      color: var(--primary-color);
    }

    /* Responsive */
    @media (max-width: 768px) {
      .publication-title {
        font-size: 1.75rem;
      }

      .hero-buttons {
        justify-content: center;
      }

      .nav-content {
        justify-content: flex-start;
      }

      .key-points-grid {
        grid-template-columns: 1fr;
      }

      .results-grid {
        grid-template-columns: repeat(2, 1fr);
      }
    }

    /* Animations */
    .fade-in {
      opacity: 0;
      transform: translateY(20px);
      animation: fadeIn 0.6s forwards;
    }

    @keyframes fadeIn {
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .stagger-1 { animation-delay: 0.1s; }
    .stagger-2 { animation-delay: 0.2s; }
    .stagger-3 { animation-delay: 0.3s; }
    .stagger-4 { animation-delay: 0.4s; }
  </style>
</head>
<body>

  <!-- Hero Section -->
  <section class="hero-section">
    <div class="hero-content">
      <h1 class="publication-title fade-in">A Transparent Pipeline for Identifying Sexism in Social Media: Combining Explainability with Model Prediction</h1>

      <div class="authors-list fade-in stagger-1">
        <strong>Hadi Mohammadi</strong>, Anastasia Giachanou, Ayoub Bagheri
      </div>

      <div class="affiliation fade-in stagger-2">
        Utrecht University, The Netherlands
      </div>

      <div class="venue fade-in stagger-2">
        Applied Sciences Journal, Volume 14, Issue 19, 2024
      </div>

      <div class="hero-buttons fade-in stagger-3">
        <a href="https://www.mdpi.com/2076-3417/14/19/8620" class="hero-button">
          <i class="fas fa-file-pdf"></i> Read Paper
        </a>
        <a href="https://github.com/mohammadi-hadi/Explainable-Sexim-Detection" class="hero-button">
          <i class="fab fa-github"></i> Code
        </a>
        <a href="https://www.mdpi.com/2076-3417/14/19/8620" class="hero-button">
          <i class="fas fa-journal-whills"></i> Journal
        </a>
        <a href="#citation" class="hero-button">
          <i class="fas fa-quote-left"></i> Cite
        </a>
        <a href="../../index.html" class="hero-button">
          <i class="fas fa-home"></i> Back Home
        </a>
      </div>
    </div>
  </section>

  <!-- Navigation -->
  <nav class="nav-bar">
    <div class="nav-content">
      <a href="#abstract" class="nav-link">Abstract</a>
      <a href="#contributions" class="nav-link">Key Contributions</a>
      <a href="#methodology" class="nav-link">Methodology</a>
      <a href="#results" class="nav-link">Results</a>
      <a href="#resources" class="nav-link">Resources</a>
      <a href="#citation" class="nav-link">Citation</a>
    </div>
  </nav>

  <!-- Abstract Section -->
  <section id="abstract" class="content-section">
    <h2 class="section-header" data-aos="fade-up">Abstract</h2>
    <div class="abstract-container" data-aos="fade-up" data-aos-delay="100">
      <div class="abstract-text">
        <p>
          Sexism, a form of discrimination based on gender, is increasingly prevalent on social media platforms, where it often manifests as hate speech targeted at individuals or groups based on their gender. While machine learning models can detect such content, their "black box" nature obscures their decision-making processes, making it difficult for users to understand why certain posts are flagged as sexist.
        </p>
        <p>
          This paper addresses the critical need for transparency in automated sexism detection by proposing an explainable pipeline that combines accurate classification with interpretable explanations. We demonstrate that incorporating explainability techniques like LIME and SHAP not only maintains high detection accuracy but also provides valuable insights into model behavior, revealing which words and phrases most strongly indicate sexist content.
        </p>
        <p>
          Our comprehensive evaluation on the EXIST 2021 dataset shows that our transparent approach achieves an F1-score of 0.82 while providing clear, understandable explanations for each prediction. This dual focus on accuracy and interpretability makes our system particularly suitable for real-world deployment, where understanding the reasoning behind content moderation decisions is crucial for both platform operators and users.
        </p>
      </div>
    </div>
  </section>

  <!-- Key Contributions -->
  <section id="contributions" class="content-section">
    <h2 class="section-header" data-aos="fade-up">Key Contributions</h2>
    <div class="key-points-grid">
      <div class="key-point-card" data-aos="fade-up" data-aos-delay="100">
        <div class="key-point-icon">
          <i class="fas fa-project-diagram"></i>
        </div>
        <h3 class="key-point-title">Transparent Pipeline</h3>
        <p class="key-point-description">
          A comprehensive pipeline that integrates multiple explainability techniques (LIME, SHAP, attention weights) with state-of-the-art classification models for sexism detection.
        </p>
      </div>

      <div class="key-point-card" data-aos="fade-up" data-aos-delay="200">
        <div class="key-point-icon">
          <i class="fas fa-chart-bar"></i>
        </div>
        <h3 class="key-point-title">Multi-Model Evaluation</h3>
        <p class="key-point-description">
          Evaluation of various models including traditional ML (SVM, Random Forest) and deep learning approaches (BERT, RoBERTa) to identify the best balance between performance and explainability.
        </p>
      </div>

      <div class="key-point-card" data-aos="fade-up" data-aos-delay="300">
        <div class="key-point-icon">
          <i class="fas fa-language"></i>
        </div>
        <h3 class="key-point-title">Linguistic Analysis</h3>
        <p class="key-point-description">
          Through explainability techniques, we identify key linguistic patterns and markers that indicate sexist content, providing insights for researchers and content moderators.
        </p>
      </div>

      <div class="key-point-card" data-aos="fade-up" data-aos-delay="400">
        <div class="key-point-icon">
          <i class="fas fa-code"></i>
        </div>
        <h3 class="key-point-title">Practical Implementation</h3>
        <p class="key-point-description">
          A fully implemented system with code and guidelines for deployment, making our approach accessible to practitioners and researchers.
        </p>
      </div>
    </div>
  </section>

  <!-- Methodology -->
  <section id="methodology" class="content-section">
    <h2 class="section-header" data-aos="fade-up">Methodology</h2>
    <div class="methodology-container" data-aos="fade-up" data-aos-delay="100">
      <h3 class="methodology-title">Pipeline Architecture</h3>
      <div class="methodology-timeline">
        <div class="timeline-item">
          <h4 class="timeline-title">1. Data Preprocessing</h4>
          <p class="timeline-description">
            Text cleaning, normalization, and feature extraction tailored for social media content.
          </p>
        </div>

        <div class="timeline-item">
          <h4 class="timeline-title">2. Model Training</h4>
          <p class="timeline-description">
            Training multiple classifiers with different architectures to compare performance and explainability trade-offs.
          </p>
        </div>

        <div class="timeline-item">
          <h4 class="timeline-title">3. Explainability Generation</h4>
          <p class="timeline-description">
            Applying LIME for local explanations and SHAP for global feature importance analysis.
          </p>
        </div>

        <div class="timeline-item">
          <h4 class="timeline-title">4. Explanation Visualization</h4>
          <p class="timeline-description">
            Creating intuitive visualizations that highlight important words and their contribution to the prediction.
          </p>
        </div>
      </div>

      <h3 class="methodology-title">Explainability Techniques</h3>
      <ul class="technique-list">
        <li class="technique-item">
          <div class="technique-icon">
            <i class="fas fa-search"></i>
          </div>
          <div class="technique-content">
            <div class="technique-name">LIME (Local Interpretable Model-agnostic Explanations)</div>
            <div class="technique-desc">Provides instance-level explanations by approximating the model locally.</div>
          </div>
        </li>
        <li class="technique-item">
          <div class="technique-icon">
            <i class="fas fa-balance-scale"></i>
          </div>
          <div class="technique-content">
            <div class="technique-name">SHAP (SHapley Additive exPlanations)</div>
            <div class="technique-desc">Offers both local and global explanations based on game theory principles.</div>
          </div>
        </li>
        <li class="technique-item">
          <div class="technique-icon">
            <i class="fas fa-eye"></i>
          </div>
          <div class="technique-content">
            <div class="technique-name">Attention Visualization</div>
            <div class="technique-desc">For transformer-based models, we visualize attention weights to understand model focus.</div>
          </div>
        </li>
      </ul>
    </div>
  </section>

  <!-- Results -->
  <section id="results" class="content-section">
    <h2 class="section-header" data-aos="fade-up">Results</h2>

    <div class="results-grid" data-aos="fade-up" data-aos-delay="100">
      <div class="result-card">
        <div class="result-number">0.82</div>
        <div class="result-label">F1-Score (RoBERTa)</div>
      </div>

      <div class="result-card">
        <div class="result-number">0.78</div>
        <div class="result-label">F1-Score (ML + SHAP)</div>
      </div>

      <div class="result-card">
        <div class="result-number">2-3s</div>
        <div class="result-label">Explainability Overhead</div>
      </div>

      <div class="result-card">
        <div class="result-number">EXIST</div>
        <div class="result-label">2021 Dataset</div>
      </div>
    </div>

    <div class="results-details" data-aos="fade-up" data-aos-delay="200">
      <ul>
        <li>The RoBERTa-based model achieves the best performance with an F1-score of 0.82</li>
        <li>Traditional ML models with SHAP explanations provide the most interpretable results while maintaining competitive accuracy (F1: 0.78)</li>
        <li>Key indicators of sexist content include gender-specific slurs, stereotypical role assignments, and objectifying language</li>
        <li>Combining multiple explainability techniques provides complementary insights - LIME excels at instance-level explanations while SHAP better captures overall model behavior</li>
      </ul>
    </div>
  </section>

  <!-- Resources -->
  <section id="resources" class="content-section">
    <h2 class="section-header" data-aos="fade-up">Code and Resources</h2>
    <div class="resources-grid" data-aos="fade-up" data-aos-delay="100">
      <div class="resource-item">
        <div class="resource-icon">
          <i class="fas fa-code"></i>
        </div>
        <span class="resource-text">Complete implementation of the transparent pipeline</span>
      </div>
      <div class="resource-item">
        <div class="resource-icon">
          <i class="fas fa-brain"></i>
        </div>
        <span class="resource-text">Pre-trained models for immediate use</span>
      </div>
      <div class="resource-item">
        <div class="resource-icon">
          <i class="fas fa-book"></i>
        </div>
        <span class="resource-text">Jupyter notebooks with examples and tutorials</span>
      </div>
      <div class="resource-item">
        <div class="resource-icon">
          <i class="fas fa-flask"></i>
        </div>
        <span class="resource-text">Scripts for reproducing all experimental results</span>
      </div>
    </div>
    <a href="https://github.com/mohammadi-hadi/Explainable-Sexim-Detection" class="resource-link" data-aos="fade-up" data-aos-delay="200">
      <i class="fab fa-github"></i> Visit GitHub Repository <i class="fas fa-arrow-right"></i>
    </a>
  </section>

  <!-- Citation -->
  <section id="citation" class="content-section">
    <h2 class="section-header" data-aos="fade-up">Citation</h2>
    <div class="citation-box" data-aos="fade-up" data-aos-delay="100">
      <button class="copy-button" onclick="copyToClipboard()">
        <i class="fas fa-copy"></i> Copy
      </button>
      <pre class="citation-code">@article{mohammadi2024transparent,
  title={A Transparent Pipeline for Identifying Sexism in Social Media: Combining Explainability with Model Prediction},
  author={Mohammadi, Hadi and Giachanou, Anastasia and Bagheri, Ayoub},
  journal={Applied Sciences},
  volume={14},
  number={19},
  pages={8620},
  year={2024},
  publisher={MDPI}
}</pre>
    </div>
  </section>

  <!-- Footer -->
  <footer class="paper-footer">
    <div class="footer-content">
      <div class="footer-links">
        <a href="../../index.html" class="footer-link">
          <i class="fas fa-home"></i>
        </a>
        <a href="https://github.com/mohammadi-hadi" class="footer-link">
          <i class="fab fa-github"></i>
        </a>
        <a href="https://www.linkedin.com/in/hadi-mohammadi-phd/" class="footer-link">
          <i class="fab fa-linkedin"></i>
        </a>
      </div>
      <p style="color: var(--text-secondary); font-size: 0.9rem;">
        © 2024 Hadi Mohammadi. This work is licensed under CC BY-SA 4.0.
      </p>
    </div>
  </footer>

  <script>
    // Initialize AOS
    AOS.init({
      duration: 800,
      once: true,
      offset: 50
    });

    // Copy to clipboard function
    function copyToClipboard() {
      const citation = document.querySelector('.citation-code').textContent;
      navigator.clipboard.writeText(citation).then(() => {
        const button = document.querySelector('.copy-button');
        button.innerHTML = '<i class="fas fa-check"></i> Copied!';
        setTimeout(() => {
          button.innerHTML = '<i class="fas fa-copy"></i> Copy';
        }, 2000);
      });
    }

    // Smooth scroll for navigation links
    document.querySelectorAll('.nav-link').forEach(link => {
      link.addEventListener('click', function(e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
      });
    });
  </script>
</body>
</html>
