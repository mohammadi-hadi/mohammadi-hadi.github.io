<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="A Transparent Pipeline for Identifying Sexism in Social Media: Combining Explainability with Model Prediction">
  <meta property="og:title" content="A Transparent Pipeline for Identifying Sexism in Social Media"/>
  <meta property="og:description" content="An explainable AI approach for detecting sexism in social media with transparent decision-making"/>
  <meta property="og:url" content="https://www.mdpi.com/2076-3417/14/19/8620"/>
  <meta name="twitter:title" content="A Transparent Pipeline for Identifying Sexism in Social Media">
  <meta name="twitter:description" content="An explainable AI approach for detecting sexism in social media with transparent decision-making">
  <meta name="keywords" content="Sexism Detection, Explainable AI, Social Media, NLP, LIME, SHAP, Hate Speech">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>A Transparent Pipeline for Identifying Sexism in Social Media</title>
  <link rel="icon" type="image/x-icon" href="../../Logo.png">
  <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:opsz,wght@8..60,400;8..60,600;8..60,700&family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <script defer src="static/js/fontawesome.all.min.js"></script>

  <style>
    :root {
      --text-black: #000000;
      --text-dark: #1a1a1a;
      --text-primary: #2d2d2d;
      --text-secondary: #555555;
      --text-muted: #777777;
      --bg-white: #ffffff;
      --bg-light: #fafafa;
      --bg-subtle: #f5f5f5;
      --border: #e0e0e0;
      --border-dark: #cccccc;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
      color: var(--text-primary);
      line-height: 1.7;
      background-color: var(--bg-white);
    }

    /* Navigation Bar */
    .nav-bar {
      background: var(--bg-white);
      border-bottom: 1px solid var(--border);
      position: sticky;
      top: 0;
      z-index: 100;
    }

    .nav-content {
      max-width: 900px;
      margin: 0 auto;
      padding: 1rem 2rem;
      display: flex;
      gap: 2rem;
      align-items: center;
      overflow-x: auto;
    }

    .nav-back {
      color: var(--text-black);
      text-decoration: none;
      font-weight: 600;
      font-size: 0.9rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      white-space: nowrap;
    }

    .nav-back:hover {
      text-decoration: underline;
    }

    .nav-links {
      display: flex;
      gap: 1.5rem;
      margin-left: auto;
    }

    .nav-link {
      color: var(--text-secondary);
      text-decoration: none;
      font-size: 0.9rem;
      white-space: nowrap;
      transition: color 0.2s;
    }

    .nav-link:hover {
      color: var(--text-black);
    }

    /* Paper Header */
    .paper-header {
      max-width: 900px;
      margin: 0 auto;
      padding: 4rem 2rem 3rem;
      border-bottom: 1px solid var(--border);
    }

    .paper-meta {
      font-size: 0.85rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 1.5rem;
    }

    .paper-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 2.25rem;
      font-weight: 700;
      color: var(--text-black);
      line-height: 1.25;
      margin-bottom: 1.5rem;
    }

    .paper-authors {
      font-size: 1.1rem;
      color: var(--text-primary);
      margin-bottom: 0.5rem;
    }

    .paper-authors strong {
      font-weight: 600;
    }

    .paper-affiliation {
      font-size: 0.95rem;
      color: var(--text-secondary);
      margin-bottom: 0.5rem;
    }

    .paper-venue {
      font-size: 0.95rem;
      color: var(--text-muted);
      font-style: italic;
      margin-bottom: 2rem;
    }

    .paper-links {
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
    }

    .paper-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.6rem 1.25rem;
      background: var(--text-black);
      color: var(--bg-white);
      text-decoration: none;
      font-size: 0.9rem;
      font-weight: 500;
      transition: background 0.2s;
    }

    .paper-link:hover {
      background: var(--text-dark);
    }

    .paper-link.secondary {
      background: var(--bg-white);
      color: var(--text-black);
      border: 1px solid var(--text-black);
    }

    .paper-link.secondary:hover {
      background: var(--bg-subtle);
    }

    /* Content Sections */
    .content-section {
      max-width: 900px;
      margin: 0 auto;
      padding: 3rem 2rem;
      border-bottom: 1px solid var(--border);
    }

    .content-section:last-of-type {
      border-bottom: none;
    }

    .section-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 1.5rem;
      font-weight: 700;
      color: var(--text-black);
      margin-bottom: 1.5rem;
      padding-bottom: 0.75rem;
      border-bottom: 2px solid var(--text-black);
      display: inline-block;
    }

    /* Abstract */
    .abstract-text {
      color: var(--text-primary);
      line-height: 1.85;
      text-align: justify;
    }

    .abstract-text p {
      margin-bottom: 1.25rem;
    }

    .abstract-text p:last-child {
      margin-bottom: 0;
    }

    /* Contributions Grid */
    .contributions-grid {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 2rem;
    }

    .contribution-item {
      padding-left: 1.5rem;
      border-left: 3px solid var(--text-black);
    }

    .contribution-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 1.1rem;
      font-weight: 600;
      color: var(--text-black);
      margin-bottom: 0.5rem;
    }

    .contribution-desc {
      color: var(--text-secondary);
      font-size: 0.95rem;
      line-height: 1.6;
    }

    /* Methodology Steps */
    .methodology-steps {
      counter-reset: step;
      margin-bottom: 2rem;
    }

    .step-item {
      display: flex;
      gap: 1.5rem;
      margin-bottom: 1.5rem;
      padding-bottom: 1.5rem;
      border-bottom: 1px solid var(--border);
    }

    .step-item:last-child {
      margin-bottom: 0;
      padding-bottom: 0;
      border-bottom: none;
    }

    .step-number {
      counter-increment: step;
      flex-shrink: 0;
      width: 2.5rem;
      height: 2.5rem;
      background: var(--text-black);
      color: var(--bg-white);
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 600;
      font-size: 1rem;
    }

    .step-number::before {
      content: counter(step);
    }

    .step-content {
      flex: 1;
    }

    .step-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-weight: 600;
      color: var(--text-black);
      margin-bottom: 0.25rem;
    }

    .step-desc {
      color: var(--text-secondary);
      font-size: 0.95rem;
    }

    /* Techniques */
    .techniques-list {
      border-top: 1px solid var(--border);
      padding-top: 2rem;
    }

    .technique-item {
      display: flex;
      gap: 1.5rem;
      margin-bottom: 1.5rem;
      padding-bottom: 1.5rem;
      border-bottom: 1px solid var(--border);
    }

    .technique-item:last-child {
      margin-bottom: 0;
      padding-bottom: 0;
      border-bottom: none;
    }

    .technique-icon {
      flex-shrink: 0;
      width: 3rem;
      height: 3rem;
      background: var(--bg-subtle);
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1.25rem;
      color: var(--text-black);
    }

    .technique-content {
      flex: 1;
    }

    .technique-name {
      font-weight: 600;
      color: var(--text-black);
      margin-bottom: 0.25rem;
    }

    .technique-desc {
      color: var(--text-secondary);
      font-size: 0.95rem;
    }

    /* Results Grid */
    .results-grid {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 1.5rem;
      margin-bottom: 2rem;
    }

    .result-card {
      text-align: center;
      padding: 1.5rem 1rem;
      background: var(--bg-subtle);
      border-left: 3px solid var(--text-black);
    }

    .result-number {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 2rem;
      font-weight: 700;
      color: var(--text-black);
      margin-bottom: 0.25rem;
    }

    .result-label {
      color: var(--text-muted);
      font-size: 0.85rem;
    }

    /* Results Details */
    .results-details {
      padding: 1.5rem;
      background: var(--bg-subtle);
    }

    .results-details ul {
      list-style: none;
    }

    .results-details li {
      padding: 0.75rem 0;
      border-bottom: 1px solid var(--border);
      color: var(--text-secondary);
      display: flex;
      align-items: flex-start;
      gap: 0.75rem;
    }

    .results-details li:last-child {
      border-bottom: none;
    }

    .results-details li::before {
      content: '\2713';
      color: var(--text-black);
      font-weight: 600;
    }

    /* Resources */
    .resources-grid {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 1.5rem;
      margin-bottom: 2rem;
    }

    .resource-item {
      display: flex;
      gap: 1rem;
      padding: 1.25rem;
      background: var(--bg-subtle);
      border-left: 3px solid var(--text-black);
    }

    .resource-icon {
      flex-shrink: 0;
      width: 2.5rem;
      height: 2.5rem;
      background: var(--bg-white);
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1rem;
      color: var(--text-black);
    }

    .resource-text {
      color: var(--text-secondary);
      font-size: 0.95rem;
      line-height: 1.5;
    }

    .github-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      color: var(--text-black);
      text-decoration: none;
      font-weight: 600;
      font-size: 0.95rem;
      transition: opacity 0.2s;
    }

    .github-link:hover {
      opacity: 0.7;
    }

    /* Citation */
    .citation-box {
      background: var(--bg-subtle);
      border: 1px solid var(--border);
      padding: 1.5rem;
      position: relative;
    }

    .citation-code {
      font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
      font-size: 0.85rem;
      color: var(--text-primary);
      white-space: pre-wrap;
      word-break: break-all;
      line-height: 1.6;
    }

    .copy-button {
      position: absolute;
      top: 1rem;
      right: 1rem;
      padding: 0.5rem 1rem;
      background: var(--text-black);
      color: var(--bg-white);
      border: none;
      cursor: pointer;
      font-size: 0.85rem;
      font-weight: 500;
      transition: background 0.2s;
    }

    .copy-button:hover {
      background: var(--text-dark);
    }

    /* Footer */
    .paper-footer {
      background: var(--text-black);
      color: var(--bg-white);
      padding: 3rem 2rem;
      margin-top: 2rem;
    }

    .footer-content {
      max-width: 900px;
      margin: 0 auto;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .footer-links {
      display: flex;
      gap: 1.5rem;
    }

    .footer-link {
      color: var(--bg-white);
      text-decoration: none;
      font-size: 1.25rem;
      opacity: 0.8;
      transition: opacity 0.2s;
    }

    .footer-link:hover {
      opacity: 1;
    }

    .footer-copy {
      color: rgba(255, 255, 255, 0.6);
      font-size: 0.85rem;
    }

    /* Responsive */
    @media (max-width: 768px) {
      .paper-title {
        font-size: 1.75rem;
      }

      .contributions-grid {
        grid-template-columns: 1fr;
      }

      .results-grid {
        grid-template-columns: repeat(2, 1fr);
      }

      .resources-grid {
        grid-template-columns: 1fr;
      }

      .nav-links {
        display: none;
      }

      .footer-content {
        flex-direction: column;
        gap: 1.5rem;
        text-align: center;
      }
    }
  </style>
</head>
<body>

  <!-- Navigation -->
  <nav class="nav-bar">
    <div class="nav-content">
      <a href="../../Publications.html" class="nav-back">
        <i class="fas fa-arrow-left"></i> Publications
      </a>
      <div class="nav-links">
        <a href="#abstract" class="nav-link">Abstract</a>
        <a href="#contributions" class="nav-link">Contributions</a>
        <a href="#methodology" class="nav-link">Methodology</a>
        <a href="#results" class="nav-link">Results</a>
        <a href="#resources" class="nav-link">Resources</a>
        <a href="#citation" class="nav-link">Citation</a>
      </div>
    </div>
  </nav>

  <!-- Paper Header -->
  <header class="paper-header">
    <div class="paper-meta">Journal Article | Applied Sciences 2024</div>
    <h1 class="paper-title">A Transparent Pipeline for Identifying Sexism in Social Media: Combining Explainability with Model Prediction</h1>
    <div class="paper-authors">
      <strong>Hadi Mohammadi</strong>, Anastasia Giachanou, Ayoub Bagheri
    </div>
    <div class="paper-affiliation">
      Utrecht University, The Netherlands
    </div>
    <div class="paper-venue">
      Applied Sciences Journal, Volume 14, Issue 19, 2024
    </div>
    <div class="paper-links">
      <a href="https://www.mdpi.com/2076-3417/14/19/8620" class="paper-link">
        <i class="fas fa-file-pdf"></i> Read Paper
      </a>
      <a href="https://github.com/mohammadi-hadi/Explainable-Sexim-Detection" class="paper-link secondary">
        <i class="fab fa-github"></i> Code
      </a>
      <a href="https://www.mdpi.com/2076-3417/14/19/8620" class="paper-link secondary">
        <i class="fas fa-journal-whills"></i> Journal
      </a>
      <a href="#citation" class="paper-link secondary">
        <i class="fas fa-quote-left"></i> Cite
      </a>
    </div>
  </header>

  <!-- Abstract -->
  <section id="abstract" class="content-section">
    <h2 class="section-title">Abstract</h2>
    <div class="abstract-text">
      <p>
        Sexism, a form of discrimination based on gender, is increasingly prevalent on social media platforms, where it often manifests as hate speech targeted at individuals or groups based on their gender. While machine learning models can detect such content, their "black box" nature obscures their decision-making processes, making it difficult for users to understand why certain posts are flagged as sexist.
      </p>
      <p>
        This paper addresses the critical need for transparency in automated sexism detection by proposing an explainable pipeline that combines accurate classification with interpretable explanations. We demonstrate that incorporating explainability techniques like LIME and SHAP not only maintains high detection accuracy but also provides valuable insights into model behavior, revealing which words and phrases most strongly indicate sexist content.
      </p>
      <p>
        Our comprehensive evaluation on the EXIST 2021 dataset shows that our transparent approach achieves an F1-score of 0.82 while providing clear, understandable explanations for each prediction. This dual focus on accuracy and interpretability makes our system particularly suitable for real-world deployment, where understanding the reasoning behind content moderation decisions is crucial for both platform operators and users.
      </p>
    </div>
  </section>

  <!-- Key Contributions -->
  <section id="contributions" class="content-section">
    <h2 class="section-title">Key Contributions</h2>
    <div class="contributions-grid">
      <div class="contribution-item">
        <h3 class="contribution-title">Transparent Pipeline</h3>
        <p class="contribution-desc">A comprehensive pipeline that integrates multiple explainability techniques (LIME, SHAP, attention weights) with state-of-the-art classification models for sexism detection.</p>
      </div>
      <div class="contribution-item">
        <h3 class="contribution-title">Multi-Model Evaluation</h3>
        <p class="contribution-desc">Evaluation of various models including traditional ML (SVM, Random Forest) and deep learning approaches (BERT, RoBERTa) to identify the best balance between performance and explainability.</p>
      </div>
      <div class="contribution-item">
        <h3 class="contribution-title">Linguistic Analysis</h3>
        <p class="contribution-desc">Through explainability techniques, we identify key linguistic patterns and markers that indicate sexist content, providing insights for researchers and content moderators.</p>
      </div>
      <div class="contribution-item">
        <h3 class="contribution-title">Practical Implementation</h3>
        <p class="contribution-desc">A fully implemented system with code and guidelines for deployment, making our approach accessible to practitioners and researchers.</p>
      </div>
    </div>
  </section>

  <!-- Methodology -->
  <section id="methodology" class="content-section">
    <h2 class="section-title">Methodology</h2>
    <div class="methodology-steps">
      <div class="step-item">
        <div class="step-number"></div>
        <div class="step-content">
          <h3 class="step-title">Data Preprocessing</h3>
          <p class="step-desc">Text cleaning, normalization, and feature extraction tailored for social media content.</p>
        </div>
      </div>
      <div class="step-item">
        <div class="step-number"></div>
        <div class="step-content">
          <h3 class="step-title">Model Training</h3>
          <p class="step-desc">Training multiple classifiers with different architectures to compare performance and explainability trade-offs.</p>
        </div>
      </div>
      <div class="step-item">
        <div class="step-number"></div>
        <div class="step-content">
          <h3 class="step-title">Explainability Generation</h3>
          <p class="step-desc">Applying LIME for local explanations and SHAP for global feature importance analysis.</p>
        </div>
      </div>
      <div class="step-item">
        <div class="step-number"></div>
        <div class="step-content">
          <h3 class="step-title">Explanation Visualization</h3>
          <p class="step-desc">Creating intuitive visualizations that highlight important words and their contribution to the prediction.</p>
        </div>
      </div>
    </div>

    <div class="techniques-list">
      <h3 style="font-family: 'Source Serif 4', Georgia, serif; font-weight: 600; color: var(--text-black); margin-bottom: 1.5rem;">Explainability Techniques</h3>
      <div class="technique-item">
        <div class="technique-icon">
          <i class="fas fa-search"></i>
        </div>
        <div class="technique-content">
          <div class="technique-name">LIME (Local Interpretable Model-agnostic Explanations)</div>
          <div class="technique-desc">Provides instance-level explanations by approximating the model locally.</div>
        </div>
      </div>
      <div class="technique-item">
        <div class="technique-icon">
          <i class="fas fa-balance-scale"></i>
        </div>
        <div class="technique-content">
          <div class="technique-name">SHAP (SHapley Additive exPlanations)</div>
          <div class="technique-desc">Offers both local and global explanations based on game theory principles.</div>
        </div>
      </div>
      <div class="technique-item">
        <div class="technique-icon">
          <i class="fas fa-eye"></i>
        </div>
        <div class="technique-content">
          <div class="technique-name">Attention Visualization</div>
          <div class="technique-desc">For transformer-based models, we visualize attention weights to understand model focus.</div>
        </div>
      </div>
    </div>
  </section>

  <!-- Results -->
  <section id="results" class="content-section">
    <h2 class="section-title">Results</h2>
    <div class="results-grid">
      <div class="result-card">
        <div class="result-number">0.82</div>
        <div class="result-label">F1-Score (RoBERTa)</div>
      </div>
      <div class="result-card">
        <div class="result-number">0.78</div>
        <div class="result-label">F1-Score (ML + SHAP)</div>
      </div>
      <div class="result-card">
        <div class="result-number">2-3s</div>
        <div class="result-label">Explanation Time</div>
      </div>
      <div class="result-card">
        <div class="result-number">EXIST</div>
        <div class="result-label">2021 Dataset</div>
      </div>
    </div>
    <div class="results-details">
      <ul>
        <li>The RoBERTa-based model achieves the best performance with an F1-score of 0.82</li>
        <li>Traditional ML models with SHAP explanations provide the most interpretable results while maintaining competitive accuracy (F1: 0.78)</li>
        <li>Key indicators of sexist content include gender-specific slurs, stereotypical role assignments, and objectifying language</li>
        <li>Combining multiple explainability techniques provides complementary insights - LIME excels at instance-level explanations while SHAP better captures overall model behavior</li>
      </ul>
    </div>
  </section>

  <!-- Resources -->
  <section id="resources" class="content-section">
    <h2 class="section-title">Code and Resources</h2>
    <div class="resources-grid">
      <div class="resource-item">
        <div class="resource-icon">
          <i class="fas fa-code"></i>
        </div>
        <div class="resource-text">Complete implementation of the transparent pipeline</div>
      </div>
      <div class="resource-item">
        <div class="resource-icon">
          <i class="fas fa-brain"></i>
        </div>
        <div class="resource-text">Pre-trained models for immediate use</div>
      </div>
      <div class="resource-item">
        <div class="resource-icon">
          <i class="fas fa-book"></i>
        </div>
        <div class="resource-text">Jupyter notebooks with examples and tutorials</div>
      </div>
      <div class="resource-item">
        <div class="resource-icon">
          <i class="fas fa-flask"></i>
        </div>
        <div class="resource-text">Scripts for reproducing all experimental results</div>
      </div>
    </div>
    <a href="https://github.com/mohammadi-hadi/Explainable-Sexim-Detection" class="github-link">
      <i class="fab fa-github"></i> Visit GitHub Repository <i class="fas fa-arrow-right"></i>
    </a>
  </section>

  <!-- Citation -->
  <section id="citation" class="content-section">
    <h2 class="section-title">Citation</h2>
    <div class="citation-box">
      <button class="copy-button" onclick="copyToClipboard()">
        <i class="fas fa-copy"></i> Copy
      </button>
      <pre class="citation-code">@article{mohammadi2024transparent,
  title={A Transparent Pipeline for Identifying Sexism in Social Media: Combining Explainability with Model Prediction},
  author={Mohammadi, Hadi and Giachanou, Anastasia and Bagheri, Ayoub},
  journal={Applied Sciences},
  volume={14},
  number={19},
  pages={8620},
  year={2024},
  publisher={MDPI}
}</pre>
    </div>
  </section>

  <!-- Footer -->
  <footer class="paper-footer">
    <div class="footer-content">
      <div class="footer-links">
        <a href="../../index.html" class="footer-link" title="Home">
          <i class="fas fa-home"></i>
        </a>
        <a href="https://github.com/mohammadi-hadi" class="footer-link" title="GitHub">
          <i class="fab fa-github"></i>
        </a>
        <a href="https://www.linkedin.com/in/hadi-mohammadi-phd/" class="footer-link" title="LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </div>
      <p class="footer-copy">&copy; 2024 Hadi Mohammadi</p>
    </div>
  </footer>

  <script>
    function copyToClipboard() {
      const citation = document.querySelector('.citation-code').textContent;
      navigator.clipboard.writeText(citation).then(() => {
        const button = document.querySelector('.copy-button');
        button.innerHTML = '<i class="fas fa-check"></i> Copied!';
        setTimeout(() => {
          button.innerHTML = '<i class="fas fa-copy"></i> Copy';
        }, 2000);
      });
    }

    document.querySelectorAll('.nav-link').forEach(link => {
      link.addEventListener('click', function(e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
      });
    });
  </script>
</body>
</html>
