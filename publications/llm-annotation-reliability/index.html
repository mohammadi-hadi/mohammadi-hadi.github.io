<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation">
  <meta property="og:title" content="Assessing the Reliability of LLMs Annotations"/>
  <meta property="og:description" content="Investigating the reliability of LLM-generated annotations for bias detection and explainability"/>
  <meta property="og:url" content="https://arxiv.org/abs/2507.13138"/>
  <meta name="twitter:title" content="Assessing the Reliability of LLMs Annotations">
  <meta name="twitter:description" content="Investigating the reliability of LLM-generated annotations for bias detection and explainability">
  <meta name="keywords" content="LLM, Demographic Bias, Model Explanation, NLP, Sexism Detection, Annotation Reliability, XAI, Fairness">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Assessing the Reliability of LLMs Annotations</title>
  <link rel="icon" type="image/x-icon" href="../../Logo.png">
  <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:opsz,wght@8..60,400;8..60,600;8..60,700&family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <script defer src="static/js/fontawesome.all.min.js"></script>

  <style>
    :root {
      --text-black: #000000;
      --text-dark: #1a1a1a;
      --text-primary: #2d2d2d;
      --text-secondary: #555555;
      --text-muted: #777777;
      --bg-white: #ffffff;
      --bg-light: #fafafa;
      --bg-subtle: #f5f5f5;
      --border: #e0e0e0;
      --border-dark: #cccccc;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
      color: var(--text-primary);
      line-height: 1.7;
      background-color: var(--bg-white);
    }

    /* Navigation Bar */
    .nav-bar {
      background: var(--bg-white);
      border-bottom: 1px solid var(--border);
      position: sticky;
      top: 0;
      z-index: 100;
    }

    .nav-content {
      max-width: 900px;
      margin: 0 auto;
      padding: 1rem 2rem;
      display: flex;
      gap: 2rem;
      align-items: center;
      overflow-x: auto;
    }

    .nav-back {
      color: var(--text-black);
      text-decoration: none;
      font-weight: 600;
      font-size: 0.9rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      white-space: nowrap;
    }

    .nav-back:hover {
      text-decoration: underline;
    }

    .nav-links {
      display: flex;
      gap: 1.5rem;
      margin-left: auto;
    }

    .nav-link {
      color: var(--text-secondary);
      text-decoration: none;
      font-size: 0.9rem;
      white-space: nowrap;
      transition: color 0.2s;
    }

    .nav-link:hover {
      color: var(--text-black);
    }

    /* Paper Header */
    .paper-header {
      max-width: 900px;
      margin: 0 auto;
      padding: 4rem 2rem 3rem;
      border-bottom: 1px solid var(--border);
    }

    .paper-meta {
      font-size: 0.85rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 1.5rem;
    }

    .paper-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 2.25rem;
      font-weight: 700;
      color: var(--text-black);
      line-height: 1.25;
      margin-bottom: 1.5rem;
    }

    .paper-authors {
      font-size: 1.1rem;
      color: var(--text-primary);
      margin-bottom: 0.5rem;
    }

    .paper-authors strong {
      font-weight: 600;
    }

    .paper-affiliation {
      font-size: 0.95rem;
      color: var(--text-secondary);
      margin-bottom: 0.5rem;
    }

    .paper-venue {
      font-size: 0.95rem;
      color: var(--text-muted);
      font-style: italic;
      margin-bottom: 2rem;
    }

    .paper-links {
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
    }

    .paper-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.6rem 1.25rem;
      background: var(--text-black);
      color: var(--bg-white);
      text-decoration: none;
      font-size: 0.9rem;
      font-weight: 500;
      transition: background 0.2s;
    }

    .paper-link:hover {
      background: var(--text-dark);
    }

    .paper-link.secondary {
      background: var(--bg-white);
      color: var(--text-black);
      border: 1px solid var(--text-black);
    }

    .paper-link.secondary:hover {
      background: var(--bg-subtle);
    }

    /* Content Sections */
    .content-section {
      max-width: 900px;
      margin: 0 auto;
      padding: 3rem 2rem;
      border-bottom: 1px solid var(--border);
    }

    .content-section:last-of-type {
      border-bottom: none;
    }

    .section-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 1.5rem;
      font-weight: 700;
      color: var(--text-black);
      margin-bottom: 1.5rem;
      padding-bottom: 0.75rem;
      border-bottom: 2px solid var(--text-black);
      display: inline-block;
    }

    /* Abstract */
    .abstract-text {
      color: var(--text-primary);
      line-height: 1.85;
      text-align: justify;
    }

    .abstract-text p {
      margin-bottom: 1.25rem;
    }

    .abstract-text p:last-child {
      margin-bottom: 0;
    }

    /* Contributions Grid */
    .contributions-grid {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 2rem;
    }

    .contribution-item {
      padding-left: 1.5rem;
      border-left: 3px solid var(--text-black);
    }

    .contribution-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 1.1rem;
      font-weight: 600;
      color: var(--text-black);
      margin-bottom: 0.5rem;
    }

    .contribution-desc {
      color: var(--text-secondary);
      font-size: 0.95rem;
      line-height: 1.6;
    }

    /* Methodology Steps */
    .methodology-steps {
      counter-reset: step;
    }

    .step-item {
      display: flex;
      gap: 1.5rem;
      margin-bottom: 1.5rem;
      padding-bottom: 1.5rem;
      border-bottom: 1px solid var(--border);
    }

    .step-item:last-child {
      margin-bottom: 0;
      padding-bottom: 0;
      border-bottom: none;
    }

    .step-number {
      counter-increment: step;
      flex-shrink: 0;
      width: 2.5rem;
      height: 2.5rem;
      background: var(--text-black);
      color: var(--bg-white);
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 600;
      font-size: 1rem;
    }

    .step-number::before {
      content: counter(step);
    }

    .step-content {
      flex: 1;
    }

    .step-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-weight: 600;
      color: var(--text-black);
      margin-bottom: 0.25rem;
    }

    .step-desc {
      color: var(--text-secondary);
      font-size: 0.95rem;
    }

    /* Metrics Grid */
    .metrics-grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1.5rem;
      margin-top: 2rem;
      padding-top: 1.5rem;
      border-top: 1px solid var(--border);
    }

    .metric-item {
      text-align: center;
      padding: 1rem;
      background: var(--bg-subtle);
    }

    .metric-name {
      font-weight: 600;
      color: var(--text-black);
      font-size: 0.9rem;
      margin-bottom: 0.25rem;
    }

    .metric-desc {
      color: var(--text-muted);
      font-size: 0.85rem;
    }

    /* Findings */
    .finding-block {
      margin-bottom: 2rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid var(--border);
    }

    .finding-block:last-child {
      margin-bottom: 0;
      padding-bottom: 0;
      border-bottom: none;
    }

    .finding-title {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 1.15rem;
      font-weight: 600;
      color: var(--text-black);
      margin-bottom: 1rem;
    }

    .finding-list {
      list-style: none;
    }

    .finding-list li {
      padding: 0.5rem 0;
      color: var(--text-secondary);
      display: flex;
      align-items: flex-start;
      gap: 0.75rem;
    }

    .finding-list li::before {
      content: '\2014';
      color: var(--text-black);
      font-weight: 600;
    }

    /* Model Comparison */
    .model-comparison {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1.5rem;
      margin-top: 2rem;
    }

    .model-card {
      padding: 1.5rem;
      background: var(--bg-subtle);
      border-left: 3px solid var(--text-black);
    }

    .model-name {
      font-weight: 600;
      color: var(--text-black);
      margin-bottom: 0.5rem;
    }

    .model-score {
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 1.75rem;
      font-weight: 700;
      color: var(--text-black);
      margin-bottom: 0.5rem;
    }

    .model-note {
      color: var(--text-muted);
      font-size: 0.85rem;
    }

    /* Recommendations */
    .recommendations-list {
      counter-reset: rec;
    }

    .recommendation-item {
      display: flex;
      gap: 1.5rem;
      margin-bottom: 1.5rem;
      padding-bottom: 1.5rem;
      border-bottom: 1px solid var(--border);
    }

    .recommendation-item:last-child {
      margin-bottom: 0;
      padding-bottom: 0;
      border-bottom: none;
    }

    .rec-number {
      counter-increment: rec;
      flex-shrink: 0;
      width: 2rem;
      height: 2rem;
      border: 2px solid var(--text-black);
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 600;
      font-size: 0.9rem;
    }

    .rec-number::before {
      content: counter(rec);
    }

    .rec-content {
      flex: 1;
    }

    .rec-title {
      font-weight: 600;
      color: var(--text-black);
      margin-bottom: 0.25rem;
    }

    .rec-desc {
      color: var(--text-secondary);
      font-size: 0.95rem;
    }

    /* Citation */
    .citation-box {
      background: var(--bg-subtle);
      border: 1px solid var(--border);
      padding: 1.5rem;
      position: relative;
    }

    .citation-code {
      font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
      font-size: 0.85rem;
      color: var(--text-primary);
      white-space: pre-wrap;
      word-break: break-all;
      line-height: 1.6;
    }

    .copy-button {
      position: absolute;
      top: 1rem;
      right: 1rem;
      padding: 0.5rem 1rem;
      background: var(--text-black);
      color: var(--bg-white);
      border: none;
      cursor: pointer;
      font-size: 0.85rem;
      font-weight: 500;
      transition: background 0.2s;
    }

    .copy-button:hover {
      background: var(--text-dark);
    }

    /* Footer */
    .paper-footer {
      background: var(--text-black);
      color: var(--bg-white);
      padding: 3rem 2rem;
      margin-top: 2rem;
    }

    .footer-content {
      max-width: 900px;
      margin: 0 auto;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .footer-links {
      display: flex;
      gap: 1.5rem;
    }

    .footer-link {
      color: var(--bg-white);
      text-decoration: none;
      font-size: 1.25rem;
      opacity: 0.8;
      transition: opacity 0.2s;
    }

    .footer-link:hover {
      opacity: 1;
    }

    .footer-copy {
      color: rgba(255, 255, 255, 0.6);
      font-size: 0.85rem;
    }

    /* Responsive */
    @media (max-width: 768px) {
      .paper-title {
        font-size: 1.75rem;
      }

      .contributions-grid {
        grid-template-columns: 1fr;
      }

      .metrics-grid {
        grid-template-columns: 1fr;
      }

      .model-comparison {
        grid-template-columns: 1fr;
      }

      .nav-links {
        display: none;
      }

      .footer-content {
        flex-direction: column;
        gap: 1.5rem;
        text-align: center;
      }
    }
  </style>
</head>
<body>

  <!-- Navigation -->
  <nav class="nav-bar">
    <div class="nav-content">
      <a href="../../Publications.html" class="nav-back">
        <i class="fas fa-arrow-left"></i> Publications
      </a>
      <div class="nav-links">
        <a href="#abstract" class="nav-link">Abstract</a>
        <a href="#contributions" class="nav-link">Contributions</a>
        <a href="#methodology" class="nav-link">Methodology</a>
        <a href="#findings" class="nav-link">Findings</a>
        <a href="#recommendations" class="nav-link">Recommendations</a>
        <a href="#citation" class="nav-link">Citation</a>
      </div>
    </div>
  </nav>

  <!-- Paper Header -->
  <header class="paper-header">
    <div class="paper-meta">Workshop Paper | ACL 2025</div>
    <h1 class="paper-title">Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation</h1>
    <div class="paper-authors">
      <strong>Hadi Mohammadi</strong>, Tina Shahedi, Pablo Mosteiro Romero, Massimo Poesio, Ayoub Bagheri, Anastasia Giachanou
    </div>
    <div class="paper-affiliation">
      Utrecht University, The Netherlands | Queen Mary University of London, UK
    </div>
    <div class="paper-venue">
      Workshop on Gender Bias in Natural Language Processing (GeBNLP), ACL 2025
    </div>
    <div class="paper-links">
      <a href="https://arxiv.org/abs/2507.13138" class="paper-link">
        <i class="fas fa-file-pdf"></i> Read Paper
      </a>
      <a href="https://arxiv.org/abs/2507.13138" class="paper-link secondary">
        <i class="ai ai-arxiv"></i> arXiv
      </a>
      <a href="#citation" class="paper-link secondary">
        <i class="fas fa-quote-left"></i> Cite
      </a>
    </div>
  </header>

  <!-- Abstract -->
  <section id="abstract" class="content-section">
    <h2 class="section-title">Abstract</h2>
    <div class="abstract-text">
      <p>
        Large Language Models (LLMs) are increasingly used for data annotation in NLP tasks, particularly for subjective tasks like hate speech detection where human annotation is expensive and potentially traumatic. However, the reliability of LLM-generated annotations, especially in the context of demographic biases and model explanations, remains understudied. This paper presents a comprehensive evaluation of LLM annotation reliability for sexism detection, examining how demographic factors influence both annotation quality and explanation consistency.
      </p>
      <p>
        Using a mixed-effects modeling approach on the EXIST 2021 dataset, we analyze annotations from multiple state-of-the-art LLMs (GPT-4, Claude, Llama) and compare them with human annotations. Our findings reveal significant variations in annotation reliability based on the demographic context of the content, with LLMs showing systematic biases in their predictions and explanations. We also discover that while LLMs can provide plausible explanations for their annotations, these explanations often lack consistency and may not reflect the actual decision-making process.
      </p>
      <p>
        This work contributes to our understanding of when and how LLM annotations can be trusted, providing guidelines for researchers using LLMs for data annotation in sensitive domains. We propose a framework for assessing annotation reliability that considers both prediction accuracy and explanation quality, offering practical recommendations for improving LLM-based annotation pipelines.
      </p>
    </div>
  </section>

  <!-- Key Contributions -->
  <section id="contributions" class="content-section">
    <h2 class="section-title">Key Contributions</h2>
    <div class="contributions-grid">
      <div class="contribution-item">
        <h3 class="contribution-title">Reliability Assessment Framework</h3>
        <p class="contribution-desc">A comprehensive framework for evaluating LLM annotation reliability that considers both accuracy and consistency across demographic groups.</p>
      </div>
      <div class="contribution-item">
        <h3 class="contribution-title">Mixed-Effects Analysis</h3>
        <p class="contribution-desc">Advanced statistical modeling to quantify the impact of demographic factors on LLM annotation quality and identify systematic biases.</p>
      </div>
      <div class="contribution-item">
        <h3 class="contribution-title">Explanation Evaluation</h3>
        <p class="contribution-desc">Analysis of LLM-generated explanations quality and consistency, revealing discrepancies between stated reasoning and actual predictions.</p>
      </div>
      <div class="contribution-item">
        <h3 class="contribution-title">Practical Guidelines</h3>
        <p class="contribution-desc">Concrete recommendations for using LLMs in annotation tasks, including strategies for bias mitigation and quality control.</p>
      </div>
    </div>
  </section>

  <!-- Methodology -->
  <section id="methodology" class="content-section">
    <h2 class="section-title">Methodology</h2>
    <div class="methodology-steps">
      <div class="step-item">
        <div class="step-number"></div>
        <div class="step-content">
          <h3 class="step-title">Data Selection</h3>
          <p class="step-desc">Stratified sampling from EXIST 2021 to ensure balanced representation across demographic groups.</p>
        </div>
      </div>
      <div class="step-item">
        <div class="step-number"></div>
        <div class="step-content">
          <h3 class="step-title">LLM Annotation</h3>
          <p class="step-desc">Collected annotations from GPT-4, Claude, and Llama using standardized prompts with and without demographic information.</p>
        </div>
      </div>
      <div class="step-item">
        <div class="step-number"></div>
        <div class="step-content">
          <h3 class="step-title">Human Baseline</h3>
          <p class="step-desc">Expert annotators provided ground truth labels and explanations for comparison.</p>
        </div>
      </div>
      <div class="step-item">
        <div class="step-number"></div>
        <div class="step-content">
          <h3 class="step-title">Statistical Analysis</h3>
          <p class="step-desc">Mixed-effects models capture complex interactions between LLM type, demographic factors, and annotation quality.</p>
        </div>
      </div>
    </div>

    <div class="metrics-grid">
      <div class="metric-item">
        <div class="metric-name">Agreement Metrics</div>
        <div class="metric-desc">Cohen's kappa and Krippendorff's alpha</div>
      </div>
      <div class="metric-item">
        <div class="metric-name">Bias Metrics</div>
        <div class="metric-desc">Demographic parity and equalized odds</div>
      </div>
      <div class="metric-item">
        <div class="metric-name">Explanation Quality</div>
        <div class="metric-desc">Consistency, relevance, and faithfulness</div>
      </div>
    </div>
  </section>

  <!-- Key Findings -->
  <section id="findings" class="content-section">
    <h2 class="section-title">Key Findings</h2>

    <div class="finding-block">
      <h3 class="finding-title">Demographic Bias in Annotations</h3>
      <ul class="finding-list">
        <li>GPT-4 is 23% more likely to label content as sexist when targeting women</li>
        <li>Claude shows the most balanced performance across demographics</li>
        <li>All models struggle with intersectional identities</li>
      </ul>
    </div>

    <div class="finding-block">
      <h3 class="finding-title">Explanation Reliability</h3>
      <ul class="finding-list">
        <li>Only 67% of explanations are consistent with the actual prediction</li>
        <li>Explanations often cite surface features rather than semantic content</li>
        <li>Models generate more detailed explanations for false positives than true positives</li>
      </ul>
    </div>

    <div class="model-comparison">
      <div class="model-card">
        <div class="model-name">GPT-4</div>
        <div class="model-score">0.84 F1</div>
        <div class="model-note">Highest accuracy but most demographically biased</div>
      </div>
      <div class="model-card">
        <div class="model-name">Claude</div>
        <div class="model-score">0.81 F1</div>
        <div class="model-note">Best balance of accuracy and fairness</div>
      </div>
      <div class="model-card">
        <div class="model-name">Llama</div>
        <div class="model-score">0.76 F1</div>
        <div class="model-note">Most consistent explanations but lower accuracy</div>
      </div>
    </div>
  </section>

  <!-- Recommendations -->
  <section id="recommendations" class="content-section">
    <h2 class="section-title">Implications and Recommendations</h2>
    <div class="recommendations-list">
      <div class="recommendation-item">
        <div class="rec-number"></div>
        <div class="rec-content">
          <div class="rec-title">Multi-Model Ensemble</div>
          <div class="rec-desc">Use multiple LLMs and aggregate their predictions to reduce individual model biases.</div>
        </div>
      </div>
      <div class="recommendation-item">
        <div class="rec-number"></div>
        <div class="rec-content">
          <div class="rec-title">Demographic Awareness</div>
          <div class="rec-desc">Include demographic diversity checks in annotation quality control.</div>
        </div>
      </div>
      <div class="recommendation-item">
        <div class="rec-number"></div>
        <div class="rec-content">
          <div class="rec-title">Explanation Validation</div>
          <div class="rec-desc">Don't rely solely on LLM explanations; validate with human review for critical applications.</div>
        </div>
      </div>
      <div class="recommendation-item">
        <div class="rec-number"></div>
        <div class="rec-content">
          <div class="rec-title">Continuous Monitoring</div>
          <div class="rec-desc">Implement ongoing bias monitoring as LLMs are updated.</div>
        </div>
      </div>
    </div>
  </section>

  <!-- Citation -->
  <section id="citation" class="content-section">
    <h2 class="section-title">Citation</h2>
    <div class="citation-box">
      <button class="copy-button" onclick="copyToClipboard()">
        <i class="fas fa-copy"></i> Copy
      </button>
      <pre class="citation-code">@inproceedings{mohammadi2025assessing,
  title={Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation},
  author={Mohammadi, Hadi and Shahedi, Tina and Mosteiro Romero, Pablo and Poesio, Massimo and Bagheri, Ayoub and Giachanou, Anastasia},
  booktitle={Proceedings of the 6th Workshop on Gender Bias in Natural Language Processing (GeBNLP)},
  year={2025},
  organization={Association for Computational Linguistics}
}</pre>
    </div>
  </section>

  <!-- Footer -->
  <footer class="paper-footer">
    <div class="footer-content">
      <div class="footer-links">
        <a href="../../index.html" class="footer-link" title="Home">
          <i class="fas fa-home"></i>
        </a>
        <a href="https://github.com/mohammadi-hadi" class="footer-link" title="GitHub">
          <i class="fab fa-github"></i>
        </a>
        <a href="https://www.linkedin.com/in/hadi-mohammadi-phd/" class="footer-link" title="LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </div>
      <p class="footer-copy">&copy; 2025 Hadi Mohammadi</p>
    </div>
  </footer>

  <script>
    function copyToClipboard() {
      const citation = document.querySelector('.citation-code').textContent;
      navigator.clipboard.writeText(citation).then(() => {
        const button = document.querySelector('.copy-button');
        button.innerHTML = '<i class="fas fa-check"></i> Copied!';
        setTimeout(() => {
          button.innerHTML = '<i class="fas fa-copy"></i> Copy';
        }, 2000);
      });
    }

    document.querySelectorAll('.nav-link').forEach(link => {
      link.addEventListener('click', function(e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
      });
    });
  </script>
</body>
</html>
